<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DuaLLaMa Chat</title>
    <style>
        /* Dark Theme CSS - Remains the same */
        :root {
            --bg-color: #1e1e1e;
            --text-color: #e0e0e0;
            --primary-color: #4CAF50; /* Green */
            --secondary-color: #2196F3; /* Blue */
            --error-color: #f44336; /* Red */
            --container-bg: #2a2a2a;
            --input-bg: #333333;
            --border-color: #444444;
            --hover-primary: #45a049;
            --hover-secondary: #0b7dda;
            --hover-error: #d32f2f;
            --disabled-color: #555555;
            --user-bubble-bg: #0d47a1; /* Darker Blue */
            --llm1-bubble-bg: #33691e; /* Darker Green */
            --llm2-bubble-bg: #1b5e20; /* Even Darker Green */
            --scrollbar-thumb: #555;
            --scrollbar-track: #333;
            --thinking-color: #aaaaaa;
            --metadata-color: #aaaaaa; /* Color for timestamps/TPS */
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
        }
        h1, h2, h3 {
            color: var(--text-color);
        }
        .settings {
            background-color: var(--container-bg);
            padding: 15px;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.3);
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border: 1px solid var(--border-color);
        }
        .settings-basic {
            flex: 1;
        }
        .settings-row {
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }
        label {
            display: inline-block;
            width: 120px;
            font-weight: bold;
            color: var(--text-color);
        }
        input, select, textarea {
            padding: 8px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            width: 200px;
            background-color: var(--input-bg);
            color: var(--text-color);
        }
        input[type="number"] {
            width: 60px;
        }
        input::placeholder, textarea::placeholder {
            color: #888;
        }
        textarea {
            min-height: 40px; /* Adjust height for prompt textareas */
            resize: vertical;
        }
        .chat-container {
            height: 500px;
            overflow-y: auto;
            background-color: var(--container-bg);
            padding: 15px;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.3);
            border: 1px solid var(--border-color);
            scrollbar-width: thin; /* Firefox */
            scrollbar-color: var(--scrollbar-thumb) var(--scrollbar-track); /* Firefox */
        }
        /* Webkit Scrollbar */
        .chat-container::-webkit-scrollbar {
            width: 8px;
        }
        .chat-container::-webkit-scrollbar-track {
            background: var(--scrollbar-track);
            border-radius: 10px;
        }
        .chat-container::-webkit-scrollbar-thumb {
            background-color: var(--scrollbar-thumb);
            border-radius: 10px;
            border: 2px solid var(--scrollbar-track);
        }

        .message {
            margin-bottom: 15px;
            max-width: 85%;
            clear: both;
            display: flex;
            flex-direction: column;
        }
        .message.user { align-items: flex-end; }
        .message.llm1, .message.llm2 { align-items: flex-start; }

        .message-header {
            display: flex;
            align-items: center;
            margin-bottom: 3px;
            font-size: 13px;
        }
         .message.user .message-header { flex-direction: row-reverse; }

        .sender { font-weight: bold; color: #ccc; margin: 0 8px; }
        .metadata { color: var(--metadata-color); font-size: 11px; }

        .bubble {
            padding: 10px 15px;
            border-radius: 18px;
            display: inline-block;
            max-width: 100%;
            word-wrap: break-word;
            color: #ffffff;
            position: relative;
        }
         .user .bubble { background-color: var(--user-bubble-bg); border-bottom-right-radius: 4px; align-self: flex-end; }
         .llm1 .bubble { background-color: var(--llm1-bubble-bg); border-bottom-left-radius: 4px; align-self: flex-start; }
         .llm2 .bubble { background-color: var(--llm2-bubble-bg); border-bottom-left-radius: 4px; align-self: flex-start; }

        .input-area { margin-top: 20px; display: flex; gap: 10px; }
        #user-input { flex: 1; padding: 12px; border: 1px solid var(--border-color); border-radius: 20px; font-size: 16px; background-color: var(--input-bg); color: var(--text-color); }
        button { padding: 10px 20px; color: white; border: none; border-radius: 20px; cursor: pointer; font-size: 16px; transition: background-color 0.2s ease; }
        #send-button { background-color: var(--primary-color); }
        #send-button:hover { background-color: var(--hover-primary); }
        #stop-conversation { background-color: var(--error-color); }
        #stop-conversation:hover { background-color: var(--hover-error); }
        #config-button { background-color: var(--secondary-color); }
        #config-button:hover { background-color: var(--hover-secondary); }
        #save-config { background-color: var(--primary-color); }
        #save-config:hover { background-color: var(--hover-primary); }

        button:disabled { background-color: var(--disabled-color); cursor: not-allowed; }
        .thinking { font-style: italic; color: var(--thinking-color); }
        .controls { display: flex; gap: 10px; align-items: center; margin-top: 10px; }

        /* Modal styles - Remain the same */
        .modal { display: none; position: fixed; z-index: 1; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0,0,0,0.7); }
        .modal-content { background-color: var(--container-bg); margin: 5% auto; padding: 20px; border-radius: 10px; width: 80%; max-width: 600px; box-shadow: 0 4px 15px rgba(0,0,0,0.5); border: 1px solid var(--border-color); color: var(--text-color); }
        .close { color: #aaa; float: right; font-size: 28px; font-weight: bold; cursor: pointer; line-height: 1; }
        .close:hover { color: var(--text-color); }
        .config-section { margin-bottom: 20px; }
        .config-section h3 { margin-top: 0; border-bottom: 1px solid var(--border-color); padding-bottom: 5px; }
        .config-row { display: flex; margin-bottom: 10px; align-items: flex-start; /* Align items to top for textareas */ }
        .config-row label { width: 150px; padding-top: 8px; /* Align label better with input/textarea */ }
        .config-row input, .config-row select, .config-row textarea { flex: 1; background-color: var(--input-bg); color: var(--text-color); border: 1px solid var(--border-color); }
        .config-row textarea { width: calc(100% - 160px); /* Adjusted width */ min-height: 60px; resize: vertical; } /* Default textarea height */
        .config-actions { text-align: right; margin-top: 20px; }
    </style>
</head>
<body>
    <h1>DuaLLaMa</h1>

    <div class="settings">
         <div class="settings-basic">
            <div class="settings-row">
                <label for="llm1-name">Bot 1 Name:</label>
                <input type="text" id="llm1-name" value="LLaMa-1">
                <label for="llm1-port" style="margin-left: 20px;">Port:</label>
                <input type="text" id="llm1-port" value="8080" style="width: 80px;">
            </div>
            <div class="settings-row">
                <label for="llm2-name">Bot 2 Name:</label>
                <input type="text" id="llm2-name" value="LLaMa-2">
                <label for="llm2-port" style="margin-left: 20px;">Port:</label>
                <input type="text" id="llm2-port" value="8000" style="width: 80px;">
            </div>
            <div class="settings-row">
                <label for="auto-turns">Auto-turns:</label>
                <input type="number" id="auto-turns" value="3" min="0" max="10">
                <span style="margin-left: 10px;">(Exchanges between bots after user message)</span>
            </div>
        </div>
        <div>
            <button id="config-button">Advanced Settings</button>
        </div>
    </div>

    <div class="chat-container" id="chat-container">
        <!-- Chat messages will appear here -->
    </div>

    <div class="input-area">
        <input type="text" id="user-input" placeholder="Type your message here...">
        <button id="send-button">Send</button>
    </div>

    <div class="controls">
        <button id="stop-conversation" disabled>Stop Bot Conversation</button>
    </div>

    <!-- Configuration Modal -->
    <div id="config-modal" class="modal">
        <div class="modal-content">
            <span class="close">&times;</span>
            <h2>Advanced Configuration</h2>

            <div class="config-section">
                <h3>Bot 1 Settings (<span id="modal-llm1-name">LLaMa-1</span>)</h3>
                <div class="config-row">
                    <label for="llm1-temperature">Temperature:</label>
                    <input type="number" id="llm1-temperature" value="0.7" min="0" max="2" step="0.1">
                </div>
                <div class="config-row">
                    <label for="llm1-max-tokens">Max Tokens:</label>
                    <input type="number" id="llm1-max-tokens" value="1024" min="50" max="8192">
                </div>
                <div class="config-row">
                    <label for="llm1-top-p">Top P:</label>
                    <input type="number" id="llm1-top-p" value="0.9" min="0" max="1" step="0.05">
                </div>
                <div class="config-row">
                    <label for="llm1-frequency-penalty">Frequency Penalty:</label>
                    <input type="number" id="llm1-frequency-penalty" value="0" min="-2" max="2" step="0.1">
                </div>
                <div class="config-row">
                    <label for="llm1-presence-penalty">Presence Penalty:</label>
                    <input type="number" id="llm1-presence-penalty" value="0" min="-2" max="2" step="0.1">
                </div>
                 <div class="config-row">
                    <label for="llm1-system-prompt">System Prompt:</label>
                    <textarea id="llm1-system-prompt" rows="3" placeholder="Optional. Overrides general prompt for this bot."></textarea>
                </div>
            </div>

            <div class="config-section">
                <h3>Bot 2 Settings (<span id="modal-llm2-name">LLaMa-2</span>)</h3>
                <div class="config-row">
                    <label for="llm2-temperature">Temperature:</label>
                    <input type="number" id="llm2-temperature" value="0.7" min="0" max="2" step="0.1">
                </div>
                <div class="config-row">
                    <label for="llm2-max-tokens">Max Tokens:</label>
                    <input type="number" id="llm2-max-tokens" value="1024" min="50" max="8192">
                </div>
                <div class="config-row">
                    <label for="llm2-top-p">Top P:</label>
                    <input type="number" id="llm2-top-p" value="0.9" min="0" max="1" step="0.05">
                </div>
                <div class="config-row">
                    <label for="llm2-frequency-penalty">Frequency Penalty:</label>
                    <input type="number" id="llm2-frequency-penalty" value="0" min="-2" max="2" step="0.1">
                </div>
                <div class="config-row">
                    <label for="llm2-presence-penalty">Presence Penalty:</label>
                    <input type="number" id="llm2-presence-penalty" value="0" min="-2" max="2" step="0.1">
                </div>
                 <div class="config-row">
                    <label for="llm2-system-prompt">System Prompt:</label>
                    <textarea id="llm2-system-prompt" rows="3" placeholder="Optional. Overrides general prompt for this bot."></textarea>
                </div>
            </div>

            <div class="config-section">
                <h3>Context Settings</h3>
                <div class="config-row">
                    <label for="context-type">Context Type:</label>
                    <select id="context-type">
                        <option value="full">Full History</option>
                        <option value="window">Sliding Window</option>
                        <!-- <option value="summary">Summary + Recent</option> -->
                    </select>
                </div>
                <div class="config-row">
                    <label for="context-window">Context Window:</label>
                    <input type="number" id="context-window" value="10" min="1" max="50">
                    <span style="margin-left: 10px;">(messages)</span>
                </div>
                <div class="config-row">
                    <label for="system-prompt">General System Prompt:</label>
                    <textarea id="system-prompt" rows="4">You are a helpful assistant engaging in a three-way conversation.</textarea>
                </div>
            </div>

            <div class="config-actions">
                <button id="save-config">Save Settings</button>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // --- DOM Element References ---
            const chatContainer = document.getElementById('chat-container');
            const userInput = document.getElementById('user-input');
            const sendButton = document.getElementById('send-button');
            const stopButton = document.getElementById('stop-conversation');
            const configButton = document.getElementById('config-button');
            const configModal = document.getElementById('config-modal');
            const closeModalBtn = configModal.querySelector('.close');
            const saveConfigBtn = document.getElementById('save-config');
            const llm1NameInput = document.getElementById('llm1-name');
            const llm2NameInput = document.getElementById('llm2-name');
            const llm1PortInput = document.getElementById('llm1-port');
            const llm2PortInput = document.getElementById('llm2-port');
            const autoTurnsInput = document.getElementById('auto-turns');
            const modalLlm1Name = document.getElementById('modal-llm1-name'); // For modal title
            const modalLlm2Name = document.getElementById('modal-llm2-name'); // For modal title

            // --- State variables ---
            let isBotConversationActive = false;
            let currentAbortController = null;
            let chatHistory = [];
            let messageCounter = 0;

            // --- Config objects (Added systemPrompt per LLM) ---
            let llm1Config = { temperature: 0.7, max_tokens: 1024, top_p: 0.9, frequency_penalty: 0, presence_penalty: 0, systemPrompt: '' };
            let llm2Config = { temperature: 0.7, max_tokens: 1024, top_p: 0.9, frequency_penalty: 0, presence_penalty: 0, systemPrompt: '' };
            let contextConfig = { type: 'full', window: 10, systemPrompt: 'You are a helpful assistant engaging in a three-way conversation.' };

            // --- Function Definitions ---

            // Load current configuration into modal
            function loadCurrentConfig() {
                // Update modal titles with current bot names
                modalLlm1Name.textContent = llm1NameInput.value || 'LLaMa-1';
                modalLlm2Name.textContent = llm2NameInput.value || 'LLaMa-2';

                // Load Bot 1 settings
                document.getElementById('llm1-temperature').value = llm1Config.temperature;
                document.getElementById('llm1-max-tokens').value = llm1Config.max_tokens;
                document.getElementById('llm1-top-p').value = llm1Config.top_p;
                document.getElementById('llm1-frequency-penalty').value = llm1Config.frequency_penalty;
                document.getElementById('llm1-presence-penalty').value = llm1Config.presence_penalty;
                document.getElementById('llm1-system-prompt').value = llm1Config.systemPrompt; // Load specific prompt

                // Load Bot 2 settings
                document.getElementById('llm2-temperature').value = llm2Config.temperature;
                document.getElementById('llm2-max-tokens').value = llm2Config.max_tokens;
                document.getElementById('llm2-top-p').value = llm2Config.top_p;
                document.getElementById('llm2-frequency-penalty').value = llm2Config.frequency_penalty;
                document.getElementById('llm2-presence-penalty').value = llm2Config.presence_penalty;
                document.getElementById('llm2-system-prompt').value = llm2Config.systemPrompt; // Load specific prompt

                // Load Context settings
                document.getElementById('context-type').value = contextConfig.type;
                document.getElementById('context-window').value = contextConfig.window;
                document.getElementById('system-prompt').value = contextConfig.systemPrompt; // Load general prompt
            }

            // Save configuration from modal
            function saveConfiguration() {
                // Save Bot 1 settings
                llm1Config.temperature = parseFloat(document.getElementById('llm1-temperature').value);
                llm1Config.max_tokens = parseInt(document.getElementById('llm1-max-tokens').value);
                llm1Config.top_p = parseFloat(document.getElementById('llm1-top-p').value);
                llm1Config.frequency_penalty = parseFloat(document.getElementById('llm1-frequency-penalty').value);
                llm1Config.presence_penalty = parseFloat(document.getElementById('llm1-presence-penalty').value);
                llm1Config.systemPrompt = document.getElementById('llm1-system-prompt').value.trim(); // Save specific prompt

                // Save Bot 2 settings
                llm2Config.temperature = parseFloat(document.getElementById('llm2-temperature').value);
                llm2Config.max_tokens = parseInt(document.getElementById('llm2-max-tokens').value);
                llm2Config.top_p = parseFloat(document.getElementById('llm2-top-p').value);
                llm2Config.frequency_penalty = parseFloat(document.getElementById('llm2-frequency-penalty').value);
                llm2Config.presence_penalty = parseFloat(document.getElementById('llm2-presence-penalty').value);
                llm2Config.systemPrompt = document.getElementById('llm2-system-prompt').value.trim(); // Save specific prompt

                // Save Context settings
                contextConfig.type = document.getElementById('context-type').value;
                contextConfig.window = parseInt(document.getElementById('context-window').value);
                contextConfig.systemPrompt = document.getElementById('system-prompt').value.trim(); // Save general prompt

                configModal.style.display = "none";
                console.log("Configuration saved:", { llm1Config, llm2Config, contextConfig });
            }

            // Helper: Format time
            function formatTime(date) {
                return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
            }

            // Helper: Add message structure to DOM
            function addMessageStructure(sender, senderType, initialContent = '') {
                messageCounter++;
                const messageId = `msg-${messageCounter}`;
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${senderType}`;
                messageDiv.id = messageId;

                const headerDiv = document.createElement('div');
                headerDiv.className = 'message-header';
                const senderDiv = document.createElement('div');
                senderDiv.className = 'sender';
                senderDiv.textContent = sender;
                const metadataSpan = document.createElement('span');
                metadataSpan.className = 'metadata';
                metadataSpan.textContent = formatTime(new Date());

                if (senderType === 'user') {
                    headerDiv.appendChild(metadataSpan);
                    headerDiv.appendChild(senderDiv);
                } else {
                    headerDiv.appendChild(senderDiv);
                    headerDiv.appendChild(metadataSpan);
                }

                const bubbleDiv = document.createElement('div');
                bubbleDiv.className = 'bubble';
                if (initialContent === 'Thinking...') {
                    bubbleDiv.classList.add('thinking');
                }
                bubbleDiv.textContent = initialContent;

                messageDiv.appendChild(headerDiv);
                messageDiv.appendChild(bubbleDiv);
                chatContainer.appendChild(messageDiv);
                chatContainer.scrollTop = chatContainer.scrollHeight;
                return messageDiv;
            }

            // Helper: Update full message content
            function updateMessageContent(messageElement, content) {
                const bubble = messageElement.querySelector('.bubble');
                if (bubble) {
                    bubble.textContent = content;
                    bubble.classList.remove('thinking');
                }
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }

            // Helper: Append token to streaming message
            function appendMessageContent(messageElement, token) {
                const bubble = messageElement.querySelector('.bubble');
                if (bubble) {
                    if (bubble.classList.contains('thinking')) {
                        bubble.textContent = '';
                        bubble.classList.remove('thinking');
                    }
                    bubble.textContent += token;
                    chatContainer.scrollTop = chatContainer.scrollHeight;
                }
            }

             // Helper: Append TPS info to metadata
            function appendTpsInfo(messageElement, tpsInfo) {
                if (!tpsInfo || typeof tpsInfo.tps !== 'number' || !isFinite(tpsInfo.tps)) return;
                const metadataSpan = messageElement.querySelector('.metadata');
                if (metadataSpan && !metadataSpan.textContent.includes('TPS')) {
                    metadataSpan.textContent += ` | ${tpsInfo.tps.toFixed(1)} TPS`;
                    if (tpsInfo.tokenCount > 0) {
                        metadataSpan.title = `${tpsInfo.tokenCount} tokens in ${tpsInfo.duration.toFixed(2)}s`;
                    }
                }
            }

            // Helper: Prepare context string (formats history ONLY)
            function prepareContext(history) {
                let contextMessages;
                if (contextConfig.type === 'full') {
                    contextMessages = history;
                } else if (contextConfig.type === 'window') {
                    contextMessages = history.slice(-contextConfig.window);
                } else { // Default to full if type is unrecognized
                    contextMessages = history;
                }
                // Just format the history, system prompt added later
                return contextMessages.map(msg => `${msg.role}: ${msg.content}`).join('\n');
            }

            // Helper: Set UI control states
            function setControlsState(isGenerating) {
                sendButton.disabled = isGenerating;
                userInput.disabled = isGenerating;
                stopButton.disabled = !isGenerating;
                configButton.disabled = isGenerating;
                llm1NameInput.disabled = isGenerating;
                llm1PortInput.disabled = isGenerating;
                llm2NameInput.disabled = isGenerating;
                llm2PortInput.disabled = isGenerating;
                autoTurnsInput.disabled = isGenerating;
            }

            // Core: Query LLM with Streaming & TPS
            async function queryLLMStream(port, prompt, config, messageElement) {
                currentAbortController = new AbortController();
                let accumulatedContent = "";
                let predictedTokenCount = 0;
                let tpsInfo = null;
                const startTime = performance.now();

                try {
                    const response = await fetch(`http://localhost:${port}/completion`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', },
                        body: JSON.stringify({
                            prompt: prompt,
                            temperature: config.temperature,
                            n_predict: config.max_tokens,
                            top_p: config.top_p,
                            frequency_penalty: config.frequency_penalty,
                            presence_penalty: config.presence_penalty,
                            stream: true
                            // Note: Sending the 'system prompt' directly here isn't standard for llama.cpp server's /completion
                            // It's usually handled by prepending it to the main 'prompt' string, as done in botConversationTurn.
                        }),
                        signal: currentAbortController.signal
                    });

                    if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
                    if (!response.body) throw new Error('Response body is null');

                    const reader = response.body.getReader();
                    const decoder = new TextDecoder();
                    let partialLine = '';

                    while (true) {
                        const { value, done } = await reader.read();
                        if (done) break;

                        const chunk = decoder.decode(value, { stream: true });
                        const lines = (partialLine + chunk).split('\n');
                        partialLine = lines.pop() || '';

                        for (const line of lines) {
                            if (line.startsWith('data: ')) {
                                try {
                                    const jsonData = JSON.parse(line.substring(6));
                                    if (jsonData.content) {
                                        accumulatedContent += jsonData.content;
                                        appendMessageContent(messageElement, jsonData.content);
                                    }
                                    if (jsonData.stop === true) {
                                        console.log("LLM stream finished. Data:", jsonData);
                                        if (jsonData.timings && typeof jsonData.timings.predicted_n === 'number') {
                                            predictedTokenCount = jsonData.timings.predicted_n;
                                            console.log(`Predicted tokens: ${predictedTokenCount}`);
                                        } else {
                                             console.log("Token count (predicted_n) not found in final message timings.");
                                        }
                                    }
                                } catch (e) {
                                    console.warn('Failed to parse JSON chunk:', line, e);
                                }
                            }
                        }
                    }
                } catch (error) {
                     if (error.name === 'AbortError') {
                        console.log('Fetch aborted by user.');
                        accumulatedContent += " [Stopped]";
                        updateMessageContent(messageElement, accumulatedContent || "[Stopped]");
                     } else {
                         console.error('Error querying LLM:', error);
                         const errorText = `Error: ${error.message}. Check LLaMa server on port ${port}.`;
                         updateMessageContent(messageElement, errorText);
                         accumulatedContent = errorText; // Mark as error, not added to history
                     }
                } finally {
                     currentAbortController = null;
                     const endTime = performance.now();
                     const durationMs = endTime - startTime;
                     const durationSec = durationMs / 1000;
                     console.log(`Stream duration: ${durationSec.toFixed(2)}s`);

                     if (predictedTokenCount > 0 && durationSec > 0.01) {
                         const tps = predictedTokenCount / durationSec;
                         tpsInfo = { tokenCount: predictedTokenCount, duration: durationSec, tps: tps };
                         console.log(`Calculated TPS: ${tps.toFixed(1)}`);
                     } else if (predictedTokenCount > 0) {
                         console.log("Duration too short for TPS.");
                         tpsInfo = { tokenCount: predictedTokenCount, duration: durationSec, tps: Infinity };
                     } else {
                         console.log("Could not calculate TPS.");
                     }
                }
                // Update one last time to ensure full content is shown, even if empty
                updateMessageContent(messageElement, accumulatedContent || "[Empty Response]");
                return { content: accumulatedContent, tpsInfo: tpsInfo };
            }

            // Core: Handle a single bot's turn
            async function botConversationTurn(currentSpeaker, otherSpeaker, currentPort, otherPort, currentConfig, turnsLeft) {
                if (!isBotConversationActive) return;

                const llm1Name = llm1NameInput.value || 'LLaMa-1'; // Get current names
                const llm2Name = llm2NameInput.value || 'LLaMa-2';

                const messageElement = addMessageStructure(currentSpeaker, currentSpeaker === llm1Name ? 'llm1' : 'llm2', 'Thinking...');

                // --- Determine the active system prompt ---
                let activeSystemPrompt = (currentConfig.systemPrompt && currentConfig.systemPrompt.trim())
                                        ? currentConfig.systemPrompt.trim() // Use specific if available
                                        : contextConfig.systemPrompt.trim(); // Fallback to general
                // Provide a minimal default if both are empty
                if (!activeSystemPrompt) {
                    activeSystemPrompt = "You are a helpful AI assistant.";
                }
                // --- ---

                const historyContext = prepareContext(chatHistory); // Get history formatted

                // Construct the final prompt including the chosen system prompt
                const prompt = `${activeSystemPrompt}\n\nThe following is a conversation between a user, ${llm1Name}, and ${llm2Name}.\nYou are ${currentSpeaker}. Respond to the ongoing conversation based ONLY on the preceding context. Keep your response relevant and concise.\n\n${historyContext}\n\n${currentSpeaker}:`;

                console.log(`[${currentSpeaker} Prompt] System: "${activeSystemPrompt}"`); // Log which prompt is used
                // console.log(`[${currentSpeaker} Prompt] Full: \n---\n${prompt}\n---`); // Optional: Log full prompt for debugging

                const result = await queryLLMStream(currentPort, prompt, currentConfig, messageElement);
                if (messageElement && result.tpsInfo) {
                    appendTpsInfo(messageElement, result.tpsInfo);
                }

                if (!isBotConversationActive) { // Check again after await
                    console.log(`Conversation stopped during ${currentSpeaker}'s turn.`);
                    return;
                }

                // Add valid responses to history (exclude errors, explicit stops, empty)
                if (result.content && !result.content.startsWith("Error:") && result.content !== "[Stopped]" && result.content !== "[Empty Response]") {
                    chatHistory.push({ role: currentSpeaker, content: result.content });
                } else {
                    console.log(`[${currentSpeaker}] Response not added to history: "${result.content}"`);
                }

                // Continue or end
                if (turnsLeft > 0 && isBotConversationActive) {
                    setTimeout(() => {
                        if (!isBotConversationActive) return;
                        // Determine next speaker's config based on names
                        const nextIsLlm1 = otherSpeaker === llm1Name;
                        const nextConfig = nextIsLlm1 ? llm1Config : llm2Config;
                        botConversationTurn(otherSpeaker, currentSpeaker, otherPort, currentPort, nextConfig, turnsLeft - 1);
                    }, 500); // Delay between turns
                } else {
                    endBotConversation();
                }
            }

            // Core: Start the bot-to-bot conversation sequence
            function startBotConversation() {
                if (isBotConversationActive) return;
                isBotConversationActive = true;
                setControlsState(true);

                const llm1Name = llm1NameInput.value || 'LLaMa-1';
                const llm2Name = llm2NameInput.value || 'LLaMa-2';
                const llm1Port = llm1PortInput.value || '8080';
                const llm2Port = llm2PortInput.value || '8000';
                const totalTurns = parseInt(autoTurnsInput.value) * 2; // Each turn is one bot response

                 if (totalTurns <= 0) {
                     console.log("Auto-turns set to 0, not starting bot conversation.");
                     endBotConversation(); // Ensure controls are re-enabled
                     return;
                 }

                // Decide who starts: LLM1 always starts after user input
                const firstSpeaker = llm1Name;
                const secondSpeaker = llm2Name;
                const firstPort = llm1Port;
                const secondPort = llm2Port;
                const firstConfig = llm1Config;

                setTimeout(() => {
                     if (!isBotConversationActive) return;
                    // Start with the first bot, passing the total number of bot responses needed
                    botConversationTurn(firstSpeaker, secondSpeaker, firstPort, secondPort, firstConfig, totalTurns - 1);
                }, 100); // Small delay for UI update
            }

            // Core: Stop the bot-to-bot conversation
            function endBotConversation(forceStop = false) {
                if (!isBotConversationActive && !forceStop) return;
                isBotConversationActive = false;
                if (currentAbortController) {
                    currentAbortController.abort();
                    currentAbortController = null;
                }
                setControlsState(false); // Re-enable controls
                console.log("Bot conversation stopped.");
            }

             // Core: Handle user sending a message
             async function handleSendMessage() {
                const message = userInput.value.trim();
                if (message === '' || isBotConversationActive) return;

                endBotConversation(true); // Force stop any active generation before user sends
                userInput.value = '';
                chatHistory = []; // Clear history on new user message for simplicity in this example? Or keep it? Keep it for now.

                const userMessageElement = addMessageStructure('You', 'user', message);
                chatHistory.push({ role: "user", content: message });

                startBotConversation(); // Start bots based on auto-turns setting
            }

            // --- Event Listener Assignments ---

            sendButton.addEventListener('click', handleSendMessage);

            userInput.addEventListener('keypress', function(e) {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    handleSendMessage();
                }
            });

            stopButton.addEventListener('click', () => {
                 endBotConversation(true); // Force stop
            });

            configButton.onclick = function() {
                loadCurrentConfig();
                configModal.style.display = "block";
            };

            closeModalBtn.onclick = function() {
                configModal.style.display = "none";
            };

            saveConfigBtn.onclick = function() {
                saveConfiguration();
            };

            window.onclick = function(event) {
                if (event.target == configModal) {
                    configModal.style.display = "none";
                }
            };

            // --- Initial Setup ---
            setControlsState(false);

        });
    </script>
</body>
</html>